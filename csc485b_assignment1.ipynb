{"cells":[{"cell_type":"code","source":["!wget -O cpp_plugin.py https://gist.github.com/akshaykhadse/7acc91dd41f52944c6150754e5530c4b/raw/cpp_plugin.py\n","%load_ext cpp_plugin"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4TsdvUsW_1Cu","executionInfo":{"status":"ok","timestamp":1727407937474,"user_tz":420,"elapsed":1416,"user":{"displayName":"Nguyen Pham","userId":"13271317330285831470"}},"outputId":"8eeea537-0952-4286-f607-8e9fd79eb401"},"execution_count":23,"outputs":[{"output_type":"stream","name":"stdout","text":["--2024-09-27 03:32:16--  https://gist.github.com/akshaykhadse/7acc91dd41f52944c6150754e5530c4b/raw/cpp_plugin.py\n","Resolving gist.github.com (gist.github.com)... 20.205.243.166\n","Connecting to gist.github.com (gist.github.com)|20.205.243.166|:443... connected.\n","HTTP request sent, awaiting response... 301 Moved Permanently\n","Location: https://gist.githubusercontent.com/akshaykhadse/7acc91dd41f52944c6150754e5530c4b/raw/cpp_plugin.py [following]\n","--2024-09-27 03:32:16--  https://gist.githubusercontent.com/akshaykhadse/7acc91dd41f52944c6150754e5530c4b/raw/cpp_plugin.py\n","Resolving gist.githubusercontent.com (gist.githubusercontent.com)... 185.199.109.133, 185.199.110.133, 185.199.108.133, ...\n","Connecting to gist.githubusercontent.com (gist.githubusercontent.com)|185.199.109.133|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 2730 (2.7K) [text/plain]\n","Saving to: ‘cpp_plugin.py’\n","\n","cpp_plugin.py       100%[===================>]   2.67K  --.-KB/s    in 0s      \n","\n","2024-09-27 03:32:16 (43.3 MB/s) - ‘cpp_plugin.py’ saved [2730/2730]\n","\n","The cpp_plugin extension is already loaded. To reload it, use:\n","  %reload_ext cpp_plugin\n"]}]},{"cell_type":"code","execution_count":24,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dclGnLGAgbtH","outputId":"d3c3d8b9-8155-4267-fa0e-e5cfc4027d44","executionInfo":{"status":"ok","timestamp":1727407944104,"user_tz":420,"elapsed":6632,"user":{"displayName":"Nguyen Pham","userId":"13271317330285831470"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting git+https://github.com/andreinechaev/nvcc4jupyter.git\n","  Cloning https://github.com/andreinechaev/nvcc4jupyter.git to /tmp/pip-req-build-bch1onrp\n","  Running command git clone --filter=blob:none --quiet https://github.com/andreinechaev/nvcc4jupyter.git /tmp/pip-req-build-bch1onrp\n","  Resolved https://github.com/andreinechaev/nvcc4jupyter.git to commit 28f872a2f99a1b201bcd0db14fdbc5a496b9bfd7\n","  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n","  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n","  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","The nvcc4jupyter extension is already loaded. To reload it, use:\n","  %reload_ext nvcc4jupyter\n"]}],"source":["# Load the extension that allows us to compile CUDA code in python notebooks\n","# Documentation is here: https://nvcc4jupyter.readthedocs.io/en/latest/\n","!pip install git+https://github.com/andreinechaev/nvcc4jupyter.git\n","%load_ext nvcc4jupyter"]},{"cell_type":"code","execution_count":25,"metadata":{"id":"VVbDQthwogQF","executionInfo":{"status":"ok","timestamp":1727407944104,"user_tz":420,"elapsed":5,"user":{"displayName":"Nguyen Pham","userId":"13271317330285831470"}}},"outputs":[],"source":["%%cuda_group_save -g \"source\" -n \"data_types.h\"\n","# /**\n","#  * A collection of commonly used data types throughout this project.\n","#  */\n","#pragma once\n","\n","#include <stdint.h> // uint32_t\n","\n","using element_t = uint32_t;"]},{"cell_type":"code","execution_count":26,"metadata":{"id":"ZqET4uI2ggwf","executionInfo":{"status":"ok","timestamp":1727407944104,"user_tz":420,"elapsed":5,"user":{"displayName":"Nguyen Pham","userId":"13271317330285831470"}}},"outputs":[],"source":["%%cuda_group_save -g \"source\" -n \"cuda_common.h\"\n","/**\n"," * Standard macros that can be useful for error checking.\n"," * https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__ERROR.html\n"," */\n","#pragma once\n","\n","#include <cuda.h>\n","\n","#define CUDA_CALL(exp)                                       \\\n","    do {                                                     \\\n","        cudaError res = (exp);                               \\\n","        if(res != cudaSuccess) {                             \\\n","            printf(\"Error at %s:%d\\n %s\\n\",                  \\\n","                __FILE__,__LINE__, cudaGetErrorString(res)); \\\n","           exit(EXIT_FAILURE);                               \\\n","        }                                                    \\\n","    } while(0)\n","\n","#define CHECK_ERROR(msg)                                             \\\n","    do {                                                             \\\n","        cudaError_t err = cudaGetLastError();                        \\\n","        if(cudaSuccess != err) {                                     \\\n","            printf(\"Error (%s) at %s:%d\\n %s\\n\",                     \\\n","                (msg), __FILE__, __LINE__, cudaGetErrorString(err)); \\\n","            exit(EXIT_FAILURE);                                      \\\n","        }                                                            \\\n","    } while (0)"]},{"cell_type":"code","execution_count":27,"metadata":{"id":"GY0L7rKhoVaZ","executionInfo":{"status":"ok","timestamp":1727407944104,"user_tz":420,"elapsed":4,"user":{"displayName":"Nguyen Pham","userId":"13271317330285831470"}}},"outputs":[],"source":["%%cuda_group_save -g \"source\" -n \"data_generator.h\"\n","/**\n"," * Functions for generating random input data with a fixed seed\n"," */\n","#pragma once\n","\n","#include <random>  // for std::mt19937, std::uniform_int_distribution\n","#include <vector>\n","\n","#include \"data_types.h\"\n","\n","namespace csc485b {\n","namespace a1 {\n","\n","/**\n"," * Generates and returns a vector of random uniform data of a given length, n,\n"," * for any integral type. Input range will be [0, 2n].\n"," */\n","template < typename T >\n","std::vector< T > generate_uniform( std::size_t n )\n","{\n","    // for details of random number generation, see:\n","    // https://en.cppreference.com/w/cpp/numeric/random/uniform_int_distribution\n","    std::size_t random_seed = 20240916;  // use magic seed\n","    std::mt19937 rng( random_seed );     // use mersenne twister generator\n","    std::uniform_int_distribution<> distrib(0, 2 * n);\n","\n","    std::vector< T > random_data( n ); // init array\n","    std::generate( std::begin( random_data )\n","                 , std::end  ( random_data )\n","                 , [ &rng, &distrib ](){ return static_cast< T >( distrib( rng ) ); });\n","\n","    return random_data;\n","}\n","\n","} // namespace a1\n","} // namespace csc485b"]},{"cell_type":"code","execution_count":28,"metadata":{"id":"IJOKRZuCkDh2","executionInfo":{"status":"ok","timestamp":1727407944104,"user_tz":420,"elapsed":4,"user":{"displayName":"Nguyen Pham","userId":"13271317330285831470"}}},"outputs":[],"source":["%%cuda_group_save -g \"source\" -n \"algorithm_choices.h\"\n","#pragma once\n","\n","#include <vector>\n","\n","#include \"data_types.h\"\n","\n","namespace csc485b {\n","namespace a1 {\n","namespace cpu {\n","\n","void run_cpu_baseline( std::vector< element_t > data, std::size_t switch_at, std::size_t n );\n","\n","} // namespace cpu\n","\n","\n","namespace gpu {\n","\n","void run_gpu_soln( std::vector< element_t > data, std::size_t switch_at, std::size_t n );\n","\n","} // namespace gpu\n","} // namespace a1\n","} // namespace csc485b"]},{"cell_type":"code","execution_count":29,"metadata":{"id":"V3lAuiBEhKjc","executionInfo":{"status":"ok","timestamp":1727407944104,"user_tz":420,"elapsed":4,"user":{"displayName":"Nguyen Pham","userId":"13271317330285831470"}}},"outputs":[],"source":["%%cuda_group_save -g \"source\" -n \"cpu_baseline.cu\"\n","/**\n"," * CPU methods that the GPU should outperform.\n"," */\n","\n","#include \"algorithm_choices.h\"\n","\n","#include <algorithm> // std::sort()\n","#include <chrono>    // for timing\n","#include <iostream>  // std::cout, std::endl\n","\n","namespace csc485b {\n","namespace a1      {\n","namespace cpu     {\n","\n","/**\n"," * Simple solution that just sorts the whole array with a built-in sort\n"," * function and then resorts the last portion in the opposing order with\n"," * a second call to that same built-in sort function.\n"," */\n","void opposing_sort( element_t * data, std::size_t invert_at_pos, std::size_t num_elements )\n","{\n","    std::sort( data, data + num_elements, std::less< element_t >{} );\n","    std::sort( data + invert_at_pos, data + num_elements, std::greater< element_t >{} );\n","}\n","\n","/**\n"," * Run the single-threaded CPU baseline that students are supposed to outperform\n"," * in order to obtain higher grades on this assignment. Times the execution and\n"," * prints to the standard output (e.g., the screen) that \"wall time.\" Note that\n"," * the functions takes the input by value so as to not perturb the original data\n"," * in place.\n"," */\n","void run_cpu_baseline( std::vector< element_t > data, std::size_t switch_at, std::size_t n )\n","{\n","    auto const cpu_start = std::chrono::high_resolution_clock::now();\n","    opposing_sort( data.data(), switch_at, n );\n","    auto const cpu_end = std::chrono::high_resolution_clock::now();\n","\n","    std::cout << \"CPU Baseline time: \"\n","              << std::chrono::duration_cast<std::chrono::nanoseconds>(cpu_end - cpu_start).count()\n","              << \" ns\" << std::endl;\n","\n","    for( auto const x : data ) std::cout << x << \" \"; std::cout << std::endl;\n","}\n","\n","} // namespace cpu\n","} // namespace a1\n","} // namespace csc485b"]},{"cell_type":"code","execution_count":30,"metadata":{"id":"bjTbQ3EO2NwQ","executionInfo":{"status":"ok","timestamp":1727407944104,"user_tz":420,"elapsed":4,"user":{"displayName":"Nguyen Pham","userId":"13271317330285831470"}}},"outputs":[],"source":["%%cuda_group_save -g \"source\" -n \"gpu_solution.cu\"\n","/**\n"," * The file in which you will implement your GPU solutions!\n"," */\n","\n","#include \"algorithm_choices.h\"\n","#include <chrono>    // for timing\n","#include <iostream>  // std::cout, std::endl\n","#include \"cuda_common.h\"\n","\n","namespace csc485b {\n","namespace a1 {\n","namespace gpu {\n","\n","\n","/**\n"," * The CPU baseline benefits from warm caches because the data was generated on\n"," * the CPU. Run the data through the GPU once with some arbitrary logic to\n"," * ensure that the GPU cache is warm too and the comparison is more fair.\n"," */\n","__global__\n","void warm_the_gpu(element_t *data, std::size_t invert_at_pos, std::size_t num_elements) {\n","    int const th_id = blockIdx.x * blockDim.x + threadIdx.x;\n","\n","    if (th_id < num_elements && data[th_id] > num_elements * 100) {\n","        ++data[th_id];\n","    }\n","}\n","\n","/**\n"," * Bitonic Sort for small arrays (n < 1024)\n"," */\n","__device__\n","void full_sort(element_t *data, std::size_t num_elements,std::size_t invert_at_pos ) {\n","    // Use shared memory to sort small arrays entirely within a block\n","    __shared__ element_t s_data[1024];\n","\n","    int idx = threadIdx.x;\n","\n","    // Load data into shared memory\n","    if (idx < num_elements) {\n","        s_data[idx] = data[idx];\n","    } else {\n","        s_data[idx] = INT_MAX;  // Assuming element_t is int\n","    }\n","    __syncthreads();\n","\n","    // Bitonic sort in shared memory\n","    for (unsigned int k = 2; k <= num_elements; k <<= 1) {\n","        for (unsigned int j = k >> 1; j > 0; j >>= 1) {\n","            unsigned int ixj = idx ^ j;\n","\n","            if (ixj < num_elements) {\n","                if (ixj > idx) {\n","                    if ((idx & k) == 0) {\n","                        if (s_data[idx] > s_data[ixj]) {\n","                            // Swap\n","                            element_t temp = s_data[idx];\n","                            s_data[idx] = s_data[ixj];\n","                            s_data[ixj] = temp;\n","                        }\n","                    } else {\n","                        if (s_data[idx] < s_data[ixj]) {\n","                            // Swap\n","                            element_t temp = s_data[idx];\n","                            s_data[idx] = s_data[ixj];\n","                            s_data[ixj] = temp;\n","                        }\n","                    }\n","                }\n","            }\n","            __syncthreads();\n","        }\n","    }\n","\n","    // Write sorted data back to global memory\n","    // Use the calculations to determine correct position\n","    if (idx >= invert_at_pos && idx < num_elements) {\n","        data[num_elements - idx + invert_at_pos - 1] = s_data[idx];\n","    } else if (idx < invert_at_pos && idx < num_elements) {\n","        data[idx] = s_data[idx];\n","    }\n","}\n","\n","/**\n"," * Bitonic Sort for larger arrays (n >= 1024) using shared memory\n"," */\n","__device__\n","void shared_full_sort(element_t *data, std::size_t num_elements,std::size_t invert_at_pos ) {\n","    // Each block sorts its own subarray\n","    __shared__ element_t s_data[1024];\n","\n","    int idx = blockIdx.x * blockDim.x + threadIdx.x;\n","    int local_idx = threadIdx.x;\n","\n","    // Load data into shared memory\n","    if (idx < num_elements) {\n","        s_data[local_idx] = data[idx];\n","    } else {\n","        s_data[local_idx] = INT_MAX;  // Assuming element_t is int\n","    }\n","    __syncthreads();\n","\n","    // Perform bitonic sort in shared memory\n","    // blockDim.x should be a power of 2\n","    for (unsigned int k = 2; k <= blockDim.x; k <<= 1) {\n","        for (unsigned int j = k >> 1; j > 0; j >>= 1) {\n","            unsigned int ixj = local_idx ^ j;\n","\n","            if (ixj > local_idx) {\n","                if ((local_idx & k) == 0) {\n","                    if (s_data[local_idx] > s_data[ixj]) {\n","                        // Swap\n","                        element_t temp = s_data[local_idx];\n","                        s_data[local_idx] = s_data[ixj];\n","                        s_data[ixj] = temp;\n","                    }\n","                } else {\n","                    if (s_data[local_idx] < s_data[ixj]) {\n","                        // Swap\n","                        element_t temp = s_data[local_idx];\n","                        s_data[local_idx] = s_data[ixj];\n","                        s_data[ixj] = temp;\n","                    }\n","                }\n","            }\n","            __syncthreads();\n","        }\n","    }\n","\n","    // Write sorted data back to global memory\n","    // Use the calculations to determine correct position\n","    if (idx >= invert_at_pos && idx < num_elements) {\n","        data[num_elements - idx + invert_at_pos - 1] = s_data[local_idx];\n","    } else if (idx < invert_at_pos && idx < num_elements) {\n","        data[idx] = s_data[local_idx];\n","    }\n","}\n","\n","/**\n"," * Main kernel function\n"," */\n","__global__\n","void opposing_sort(element_t *data, std::size_t invert_at_pos, std::size_t num_elements) {\n","    if (num_elements <= 1024) {\n","        full_sort(data, num_elements, invert_at_pos);\n","    } else {\n","        shared_full_sort(data, num_elements, invert_at_pos);\n","    }\n","    __syncthreads();\n","}\n","\n","/**\n"," * Performs all the logic of allocating device vectors and copying host/input\n"," * vectors to the device. Times the opposing_sort() kernel with wall time,\n"," * but excludes set up and tear down costs such as mallocs, frees, and memcpies.\n"," */\n","void run_gpu_soln(std::vector<element_t> data, std::size_t switch_at, std::size_t n) {\n","    std::size_t const threads_per_block = 1024;\n","    std::size_t const num_blocks = (n + threads_per_block - 1) / threads_per_block;\n","\n","    // Allocate arrays on the device/GPU\n","    element_t *d_data;\n","    cudaMalloc((void**)&d_data, sizeof(element_t) * n);\n","    CHECK_ERROR(\"Allocating input array on device\");\n","\n","    // Copy the input from the host to the device/GPU\n","    cudaMemcpy(d_data, data.data(), sizeof(element_t) * n, cudaMemcpyHostToDevice);\n","    CHECK_ERROR(\"Copying input array to device\");\n","\n","    // Warm the cache on the GPU for a more fair comparison\n","    warm_the_gpu<<<num_blocks, threads_per_block>>>(d_data, switch_at, n);\n","\n","    // Time the execution of the kernel that you implemented\n","    auto const kernel_start = std::chrono::high_resolution_clock::now();\n","    opposing_sort<<<num_blocks, threads_per_block>>>(d_data, switch_at, n);\n","    auto const kernel_end = std::chrono::high_resolution_clock::now();\n","    CHECK_ERROR(\"Executing kernel on device\");\n","\n","    // After the timer ends, copy the result back, free the device vector,\n","    // and echo out the timings and the results.\n","    cudaMemcpy(data.data(), d_data, sizeof(element_t) * n, cudaMemcpyDeviceToHost);\n","    CHECK_ERROR(\"Transferring result back to host\");\n","    cudaFree(d_data);\n","    CHECK_ERROR(\"Freeing device memory\");\n","\n","    std::cout << \"GPU Solution time: \"\n","              << std::chrono::duration_cast<std::chrono::nanoseconds>(kernel_end - kernel_start).count()\n","              << \" ns\" << std::endl;\n","\n","    for (auto const x : data) std::cout << x << \" \";\n","    std::cout << std::endl;\n","}\n","\n","} // namespace gpu\n","} // namespace a1\n","} // namespace csc485b\n"]},{"cell_type":"markdown","source":[],"metadata":{"id":"-E473UYf_wwg"}},{"cell_type":"code","execution_count":37,"metadata":{"id":"IRvVeK-QifnZ","executionInfo":{"status":"ok","timestamp":1727408016560,"user_tz":420,"elapsed":378,"user":{"displayName":"Nguyen Pham","userId":"13271317330285831470"}}},"outputs":[],"source":["%%cuda_group_save -g \"source\" -n \"main.cu\"\n","/**\n"," * Driver for the benchmark comparison. Generates random data,\n"," * runs the CPU baseline, and then runs your code.\n"," */\n","\n","#include <cstddef>  // std::size_t type\n","#include <iostream> // std::cout, std::endl\n","#include <vector>\n","\n","#include \"algorithm_choices.h\"\n","#include \"data_generator.h\"\n","#include \"data_types.h\"\n","#include \"cuda_common.h\"\n","\n","int main()\n","{\n","    std::size_t const n =32;\n","    std::size_t const switch_at = 3 * ( n >> 2 ) ;\n","\n","    auto data = csc485b::a1::generate_uniform< element_t >( n );\n","    csc485b::a1::cpu::run_cpu_baseline( data, switch_at, n );\n","    csc485b::a1::gpu::run_gpu_soln( data, switch_at, n );\n","\n","    return EXIT_SUCCESS;\n","}"]},{"cell_type":"code","execution_count":38,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"S7F0eVsGjUNp","outputId":"4e3416d1-4cc8-4757-afb2-3b857bea1961","executionInfo":{"status":"ok","timestamp":1727408038690,"user_tz":420,"elapsed":10612,"user":{"displayName":"Nguyen Pham","userId":"13271317330285831470"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["CPU Baseline time: 1120 ns\n","0 0 1 1 6 7 8 10 10 10 11 13 13 13 15 19 19 23 27 27 31 33 34 35 59 57 56 52 52 51 39 36 \n","GPU Solution time: 14090 ns\n","0 0 1 1 6 7 8 10 10 10 11 13 13 13 15 19 19 23 27 27 31 33 34 35 59 57 56 52 52 51 39 36 \n","\n"]}],"source":["%cuda_group_run --group \"source\" --compiler-args \"-O3 -g -std=c++20 -arch=sm_75\""]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}